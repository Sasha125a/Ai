from http.server import HTTPServer, BaseHTTPRequestHandler
import json
import re
import random
import os
import base64
from datetime import datetime
import mimetypes
import numpy as np
import pickle
from collections import defaultdict, Counter
import sqlite3
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import nltk
from nltk.stem import SnowballStemmer
from nltk.tokenize import word_tokenize
import threading
import time
import requests
from bs4 import BeautifulSoup
import urllib.parse
import asyncio
import aiohttp
import warnings
warnings.filterwarnings('ignore')

# –°–∫–∞—á–∏–≤–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∞–Ω–Ω—ã–µ NLTK
try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    nltk.download('punkt')

class WebSearch:
    """–ö–ª–∞—Å—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ"""
    
    def __init__(self):
        self.search_engines = [
            self._search_duckduckgo,
            self._search_google_suggest,
            self._search_wikipedia
        ]
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
    
    def search_internet(self, query, max_results=3):
        """–ü–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ –ø–æ –∑–∞–ø—Ä–æ—Å—É"""
        print(f"üîç –ü–æ–∏—Å–∫ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ: {query}")
        
        all_results = []
        
        for search_func in self.search_engines:
            try:
                results = search_func(query, max_results)
                if results:
                    all_results.extend(results)
                    print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —á–µ—Ä–µ–∑ {search_func.__name__}")
                    break  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–π —É—Å–ø–µ—à–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ {search_func.__name__}: {e}")
                continue
        
        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
        unique_results = []
        seen_snippets = set()
        
        for result in all_results:
            snippet = result.get('snippet', '')[:100]
            if snippet not in seen_snippets:
                seen_snippets.add(snippet)
                unique_results.append(result)
        
        return unique_results[:max_results]
    
    def _search_duckduckgo(self, query, max_results=3):
        """–ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ DuckDuckGo Instant Answer API"""
        try:
            url = "https://api.duckduckgo.com/"
            params = {
                'q': query,
                'format': 'json',
                'no_html': '1',
                'skip_disambig': '1'
            }
            
            response = self.session.get(url, params=params, timeout=10)
            data = response.json()
            
            results = []
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫—Ä–∞—Ç–∫–∏–π –æ—Ç–≤–µ—Ç
            if data.get('AbstractText'):
                results.append({
                    'title': data.get('Heading', '–û—Ç–≤–µ—Ç'),
                    'snippet': data.get('AbstractText'),
                    'source': 'DuckDuckGo',
                    'url': data.get('AbstractURL', '')
                })
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Ç–µ–º—ã
            for topic in data.get('RelatedTopics', [])[:max_results]:
                if 'Text' in topic:
                    results.append({
                        'title': topic.get('FirstURL', '').split('/')[-1].replace('_', ' '),
                        'snippet': topic['Text'],
                        'source': 'DuckDuckGo',
                        'url': topic.get('FirstURL', '')
                    })
            
            return results
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ DuckDuckGo: {e}")
            return []
    
    def _search_google_suggest(self, query, max_results=3):
        """–ò—Å–ø–æ–ª—å–∑—É–µ–º Google Suggestions –∫–∞–∫ fallback"""
        try:
            url = "http://suggestqueries.google.com/complete/search"
            params = {
                'q': query,
                'client': 'firefox',
                'hl': 'ru'
            }
            
            response = self.session.get(url, params=params, timeout=10)
            suggestions = response.json()[1]
            
            results = []
            for suggestion in suggestions[:max_results]:
                results.append({
                    'title': '–ü–æ–¥—Å–∫–∞–∑–∫–∞ Google',
                    'snippet': f"–í–æ–∑–º–æ–∂–Ω–æ, –≤—ã –∏–º–µ–ª–∏ –≤ –≤–∏–¥—É: {suggestion}",
                    'source': 'Google Suggest',
                    'url': ''
                })
            
            return results
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ Google Suggest: {e}")
            return []
    
    def _search_wikipedia(self, query, max_results=2):
        """–ü–æ–∏—Å–∫ –≤ Wikipedia"""
        try:
            # –ò—â–µ–º —Å—Ç–∞—Ç—å—é –≤ Wikipedia
            url = "https://ru.wikipedia.org/w/api.php"
            params = {
                'action': 'query',
                'list': 'search',
                'srsearch': query,
                'format': 'json',
                'srlimit': max_results
            }
            
            response = self.session.get(url, params=params, timeout=10)
            data = response.json()
            
            results = []
            for item in data.get('query', {}).get('search', [])[:max_results]:
                # –ü–æ–ª—É—á–∞–µ–º –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å—Ç–∞—Ç—å–∏
                extract_params = {
                    'action': 'query',
                    'prop': 'extracts',
                    'exintro': '1',
                    'explaintext': '1',
                    'titles': item['title'],
                    'format': 'json'
                }
                
                extract_response = self.session.get(url, params=extract_params, timeout=10)
                extract_data = extract_response.json()
                
                pages = extract_data.get('query', {}).get('pages', {})
                for page_id, page_data in pages.items():
                    if page_id != '-1' and 'extract' in page_data:
                        snippet = page_data['extract'][:300] + '...' if len(page_data['extract']) > 300 else page_data['extract']
                        results.append({
                            'title': item['title'],
                            'snippet': snippet,
                            'source': 'Wikipedia',
                            'url': f"https://ru.wikipedia.org/wiki/{urllib.parse.quote(item['title'])}"
                        })
            
            return results
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ Wikipedia: {e}")
            return []
    
    def extract_programming_info(self, search_results, original_query):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–∏"""
        programming_info = {
            'concepts': [],
            'examples': [],
            'definitions': [],
            'best_practices': []
        }
        
        for result in search_results:
            snippet = result['snippet'].lower()
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
            if any(word in snippet for word in ['—ç—Ç–æ', '–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ', '–æ–∑–Ω–∞—á–∞–µ—Ç', '–ø–æ–Ω—è—Ç–∏–µ']):
                programming_info['definitions'].append({
                    'text': result['snippet'],
                    'source': result['source'],
                    'title': result['title']
                })
            
            elif any(word in snippet for word in ['–ø—Ä–∏–º–µ—Ä', '–∫–æ–¥', '—Å–∏–Ω—Ç–∞–∫—Å–∏—Å', '—Ñ—É–Ω–∫—Ü–∏—è', '–∫–ª–∞—Å—Å']):
                programming_info['examples'].append({
                    'text': result['snippet'],
                    'source': result['source'],
                    'title': result['title']
                })
            
            elif any(word in snippet for word in ['–ª—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏', '—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏', '—Å–æ–≤–µ—Ç—ã']):
                programming_info['best_practices'].append({
                    'text': result['snippet'],
                    'source': result['source'],
                    'title': result['title']
                })
            
            else:
                programming_info['concepts'].append({
                    'text': result['snippet'],
                    'source': result['source'],
                    'title': result['title']
                })
        
        return programming_info

class LearningAI:
    """–ö–ª–∞—Å—Å –¥–ª—è –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –∏ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –ò–ò"""
    
    def __init__(self):
        self.knowledge_base = defaultdict(list)
        self.user_feedback = []
        self.conversation_patterns = []
        self.model_version = "1.0"
        self.learning_rate = 0.1
        self.stemmer = SnowballStemmer("russian")
        self.web_search = WebSearch()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∑–Ω–∞–Ω–∏–π
        self.init_knowledge_db()
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∑–Ω–∞–Ω–∏–π
        self.load_knowledge()
        
        # –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä –¥–ª—è —Ç–µ–∫—Å—Ç–∞
        self.vectorizer = TfidfVectorizer(
            max_features=1000,
            stop_words=['–∏', '–≤', '–Ω–∞', '—Å', '–ø–æ', '–¥–ª—è', '—ç—Ç–æ', '–∫–∞–∫', '—á—Ç–æ'],
            ngram_range=(1, 2)
        )
        
        # –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –Ω–∞—á–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        self.initial_training()
    
    def init_knowledge_db(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö SQLite –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∑–Ω–∞–Ω–∏–π"""
        self.conn = sqlite3.connect('ai_knowledge.db', check_same_thread=False)
        cursor = self.conn.cursor()
        
        # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS qa_patterns (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                question TEXT NOT NULL,
                answer TEXT NOT NULL,
                intent TEXT,
                entities TEXT,
                confidence REAL DEFAULT 1.0,
                usage_count INTEGER DEFAULT 0,
                success_rate REAL DEFAULT 1.0,
                source TEXT DEFAULT 'manual', -- manual, web_search, generated
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –≤–µ–±-–ø–æ–∏—Å–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS web_search_cache (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                query TEXT NOT NULL,
                title TEXT,
                snippet TEXT,
                source TEXT,
                url TEXT,
                intent TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS user_preferences (
                user_id TEXT,
                preference_type TEXT,
                preference_value TEXT,
                strength REAL DEFAULT 1.0,
                PRIMARY KEY (user_id, preference_type)
            )
        ''')
        
        # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS feedback (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                question TEXT,
                answer TEXT,
                user_feedback INTEGER, -- 1 –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π, -1 –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π, 0 –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π
                feedback_text TEXT,
                timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        self.conn.commit()
    
    def load_knowledge(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∑–Ω–∞–Ω–∏–π –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        cursor = self.conn.cursor()
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ QA –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        cursor.execute('SELECT question, answer, intent, confidence, source FROM qa_patterns')
        for question, answer, intent, confidence, source in cursor.fetchall():
            self.knowledge_base[intent].append({
                'question': question,
                'answer': answer,
                'confidence': confidence,
                'source': source
            })
    
    def initial_training(self):
        """–ù–∞—á–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –±–∞–∑–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        training_data = [
            # –ü—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ
            ("–∫–∞–∫ —Å–æ–∑–¥–∞—Ç—å –∫–ª–∞—Å—Å –≤ python", "–ò—Å–ø–æ–ª—å–∑—É–π –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ class: class MyClass:", "code_request", "python"),
            ("—á—Ç–æ —Ç–∞–∫–æ–µ —Ñ—É–Ω–∫—Ü–∏—è", "–§—É–Ω–∫—Ü–∏—è —ç—Ç–æ –±–ª–æ–∫ –∫–æ–¥–∞, –∫–æ—Ç–æ—Ä—ã–π –≤—ã–ø–æ–ª–Ω—è–µ—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—É—é –∑–∞–¥–∞—á—É", "explanation", "programming"),
            ("–∫–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç —Ü–∏–∫–ª for", "–¶–∏–∫–ª for –ø–æ–≤—Ç–æ—Ä—è–µ—Ç –¥–µ–π—Å—Ç–≤–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏", "explanation", "programming"),
            ("—á—Ç–æ —Ç–∞–∫–æ–µ –æ–æ–ø", "–û–û–ü - –æ–±—ä–µ–∫—Ç–Ω–æ-–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ, –ø–æ–¥—Ö–æ–¥ –∫ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—é", "explanation", "programming"),
            
            # –ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è
            ("–ø—Ä–∏–≤–µ—Ç", "–ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ —è –º–æ–≥—É –ø–æ–º–æ—á—å —Å –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ–º?", "greeting", ""),
            ("–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ", "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –ì–æ—Ç–æ–≤ –ø–æ–º–æ—á—å —Å –∫–æ–¥–æ–º.", "greeting", ""),
            
            # –ü—Ä–æ—â–∞–Ω–∏—è
            ("–ø–æ–∫–∞", "–î–æ —Å–≤–∏–¥–∞–Ω–∏—è! –í–æ–∑–≤—Ä–∞—â–∞–π—Ç–µ—Å—å —Å –≤–æ–ø—Ä–æ—Å–∞–º–∏ –ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—é.", "farewell", ""),
            ("–¥–æ —Å–≤–∏–¥–∞–Ω–∏—è", "–î–æ –≤—Å—Ç—Ä–µ—á–∏! –£–¥–∞—á–∏ –≤ –∫–æ–¥–∏–Ω–≥–µ!", "farewell", ""),
            
            # –ü–æ–º–æ—â—å
            ("—á—Ç–æ —Ç—ã —É–º–µ–µ—à—å", "–Ø –ø–æ–º–æ–≥–∞—é —Å –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ–º: –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–¥–∞, –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–π, —Ä–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º", "help", ""),
            ("–ø–æ–º–æ—â—å", "–Ø —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—Å—å –Ω–∞ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–∏. –ú–æ–≥—É –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥, –æ–±—ä—è—Å–Ω—è—Ç—å –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏, –ø–æ–º–æ–≥–∞—Ç—å —Å –æ—à–∏–±–∫–∞–º–∏", "help", ""),
        ]
        
        cursor = self.conn.cursor()
        for question, answer, intent, entities in training_data:
            cursor.execute('''
                INSERT OR IGNORE INTO qa_patterns (question, answer, intent, entities, source)
                VALUES (?, ?, ?, ?, 'manual')
            ''', (question, answer, intent, entities))
        
        self.conn.commit()
        self.load_knowledge()
    
    def search_and_learn(self, user_message, intent, entities, min_confidence=0.3):
        """–ü–æ–∏—Å–∫ –æ—Ç–≤–µ—Ç–∞ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π"""
        print(f"üîç –ü–æ–∏—Å–∫ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ –¥–ª—è: {user_message}")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        search_query = self._build_search_query(user_message, intent, entities)
        
        # –ò—â–µ–º –≤ –∫—ç—à–µ
        cached_result = self._get_cached_search(search_query, intent)
        if cached_result:
            print("‚úÖ –ò—Å–ø–æ–ª—å–∑—É—é –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–∏—Å–∫–∞")
            return cached_result, "web_cache"
        
        # –ò—â–µ–º –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ
        search_results = self.web_search.search_internet(search_query)
        
        if not search_results:
            print("‚ùå –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ")
            return None, "no_results"
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –Ω–∞–π–¥–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        formatted_answer = self._format_web_results(search_results, user_message, intent)
        
        if formatted_answer:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π
            self._save_web_knowledge(user_message, formatted_answer, intent, entities, search_results)
            print("‚úÖ –ù–æ–≤—ã–µ –∑–Ω–∞–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –±–∞–∑—É")
            return formatted_answer, "web_search"
        
        return None, "format_failed"
    
    def _build_search_query(self, user_message, intent, entities):
        """–§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞"""
        # –ë–∞–∑–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        query = user_message
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è
        programming_keywords = ["–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ", "–∫–æ–¥", "python", "javascript", "java", "–ø—Ä–æ–≥—Ä–∞–º–º–∞"]
        
        if intent in ['explanation', 'code_request']:
            if not any(keyword in user_message.lower() for keyword in programming_keywords):
                query = f"{user_message} –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ"
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–∏–∫—É –¥–ª—è —è–∑—ã–∫–æ–≤
        if entities.get('languages'):
            lang = entities['languages'][0]
            query = f"{user_message} {lang}"
        
        return query
    
    def _get_cached_search(self, query, intent):
        """–ü–æ–∏—Å–∫ –≤ –∫—ç—à–µ –≤–µ–±-–ø–æ–∏—Å–∫–∞"""
        cursor = self.conn.cursor()
        cursor.execute('''
            SELECT snippet, title, source 
            FROM web_search_cache 
            WHERE query = ? AND intent = ?
            ORDER BY created_at DESC 
            LIMIT 1
        ''', (query, intent))
        
        result = cursor.fetchone()
        if result:
            snippet, title, source = result
            return f"üìö {title}\n\n{snippet}\n\nüîó –ò—Å—Ç–æ—á–Ω–∏–∫: {source}"
        
        return None
    
    def _format_web_results(self, search_results, original_question, intent):
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞ –≤ –æ—Ç–≤–µ—Ç"""
        if not search_results:
            return None
        
        best_result = search_results[0]
        title = best_result.get('title', '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞')
        snippet = best_result.get('snippet', '')
        source = best_result.get('source', '–∏–Ω—Ç–µ—Ä–Ω–µ—Ç')
        
        # –û—á–∏—â–∞–µ–º –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç
        cleaned_snippet = self._clean_web_snippet(snippet, original_question)
        
        response = f"üåê **{title}**\n\n"
        response += f"{cleaned_snippet}\n\n"
        response += f"üìö *–ò—Å—Ç–æ—á–Ω–∏–∫: {source}*"
        
        # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –µ—Å–ª–∏ –µ—Å—Ç—å
        if len(search_results) > 1:
            response += "\n\nüí° **–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:**"
            for i, result in enumerate(search_results[1:3], 1):
                additional_snippet = result.get('snippet', '')[:150] + '...' if len(result.get('snippet', '')) > 150 else result.get('snippet', '')
                response += f"\n‚Ä¢ {additional_snippet}"
        
        return response
    
    def _clean_web_snippet(self, snippet, original_question):
        """–û—á–∏—Å—Ç–∫–∞ –∏ —É–ª—É—á—à–µ–Ω–∏–µ –≤–µ–±-—Å–Ω–∏–ø–ø–µ—Ç–∞"""
        # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã
        cleaned = re.sub(r'\s+', ' ', snippet).strip()
        
        # –£–¥–∞–ª—è–µ–º HTML —Ç–µ–≥–∏
        cleaned = re.sub(r'<[^>]+>', '', cleaned)
        
        # –û–±—Ä–µ–∑–∞–µ–º –¥–æ —Ä–∞–∑—É–º–Ω–æ–π –¥–ª–∏–Ω—ã
        if len(cleaned) > 500:
            cleaned = cleaned[:500] + '...'
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if "–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ" in original_question.lower() and "–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ" not in cleaned.lower():
            cleaned = f"–í –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è: {cleaned}"
        
        return cleaned
    
    def _save_web_knowledge(self, question, answer, intent, entities, search_results):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤–µ–±-–∑–Ω–∞–Ω–∏–π –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
        cursor = self.conn.cursor()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º QA –ø–∞—Ç—Ç–µ—Ä–Ω
        cursor.execute('''
            INSERT INTO qa_patterns (question, answer, intent, entities, source, confidence)
            VALUES (?, ?, ?, ?, 'web_search', 0.8)
        ''', (question, answer, intent, json.dumps(entities)))
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –≤ –∫—ç—à
        for result in search_results[:2]:  # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 2 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            cursor.execute('''
                INSERT INTO web_search_cache (query, title, snippet, source, url, intent)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (question, result.get('title'), result.get('snippet'), 
                  result.get('source'), result.get('url'), intent))
        
        self.conn.commit()
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –∫—ç—à –∑–Ω–∞–Ω–∏–π
        self.knowledge_base[intent].append({
            'question': question,
            'answer': answer,
            'confidence': 0.8,
            'source': 'web_search'
        })
    
    def find_best_response(self, user_message, intent, entities, use_web_search=True):
        """–ü–æ–∏—Å–∫ –ª—É—á—à–µ–≥–æ –æ—Ç–≤–µ—Ç–∞ —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –ø–æ–∏—Å–∫–∞ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ"""
        cursor = self.conn.cursor()
        
        # –ò—â–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        cursor.execute('''
            SELECT answer, confidence, success_rate, source
            FROM qa_patterns 
            WHERE question = ? AND intent = ?
            ORDER BY success_rate DESC, confidence DESC
            LIMIT 1
        ''', (user_message, intent))
        
        result = cursor.fetchone()
        if result:
            answer, confidence, success_rate, source = result
            if confidence * success_rate > 0.5:  # –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
                cursor.execute('''
                    UPDATE qa_patterns 
                    SET usage_count = usage_count + 1 
                    WHERE question = ? AND answer = ?
                ''', (user_message, answer))
                self.conn.commit()
                return answer, confidence * success_rate, source
        
        # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ –≤–æ–ø—Ä–æ—Å—ã –≤ –±–∞–∑–µ
        cursor.execute('''
            SELECT question, answer, confidence, success_rate, source
            FROM qa_patterns 
            WHERE intent = ?
        ''', (intent,))
        
        best_match = None
        best_similarity = 0
        best_source = None
        
        for q, a, conf, success, source in cursor.fetchall():
            similarity = self._calculate_similarity(user_message, q)
            weighted_similarity = similarity * conf * success
            
            if weighted_similarity > best_similarity:
                best_similarity = weighted_similarity
                best_match = a
                best_source = source
        
        if best_match and best_similarity > 0.3:
            return best_match, best_similarity, best_source
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –≤ –±–∞–∑–µ –∏ —Ä–∞–∑—Ä–µ—à–µ–Ω –≤–µ–±-–ø–æ–∏—Å–∫
        if use_web_search and intent in ['explanation', 'code_request', 'learning_path']:
            web_answer, web_source = self.search_and_learn(user_message, intent, entities)
            if web_answer:
                return web_answer, 0.7, web_source
        
        return None, 0.0, None
    
    def _calculate_similarity(self, text1, text2):
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ö–æ–∂–µ—Å—Ç–∏ –º–µ–∂–¥—É –¥–≤—É–º—è —Ç–µ–∫—Å—Ç–∞–º–∏"""
        words1 = set(self._preprocess_text(text1))
        words2 = set(self._preprocess_text(text2))
        
        if not words1 or not words2:
            return 0.0
        
        intersection = words1.intersection(words2)
        union = words1.union(words2)
        
        return len(intersection) / len(union)
    
    def _preprocess_text(self, text):
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
        text = text.lower()
        text = re.sub(r'[^\w\s]', ' ', text)
        words = text.split()
        words = [self.stemmer.stem(word) for word in words if len(word) > 2]
        return words

class SmartAI:
    def __init__(self):
        self.conversation_history = []
        self.user_profile = {
            'interests': set(),
            'skill_level': 'beginner',
            'preferred_languages': set(),
            'user_id': 'default'
        }
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã –æ–±—É—á–µ–Ω–∏—è —Å –≤–µ–±-–ø–æ–∏—Å–∫–æ–º
        self.learning_ai = LearningAI()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—É—á–µ–Ω–∏—è
        self.learning_stats = {
            'conversations_processed': 0,
            'patterns_learned': 0,
            'web_searches': 0,
            'success_rate': 1.0
        }
        
        self.programming_languages = {
            'python': {'name': 'Python', 'paradigms': ['object-oriented', 'functional', 'imperative']},
            'javascript': {'name': 'JavaScript', 'paradigms': ['object-oriented', 'functional', 'event-driven']},
            'java': {'name': 'Java', 'paradigms': ['object-oriented', 'imperative']},
        }
    
    def analyze_intent(self, message):
        message_lower = message.lower()
        
        intents = {
            'greeting': any(word in message_lower for word in ['–ø—Ä–∏–≤–µ—Ç', '–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π', 'hello', 'hi', '–¥–æ–±—Ä—ã–π']),
            'farewell': any(word in message_lower for word in ['–ø–æ–∫–∞', '–¥–æ —Å–≤–∏–¥–∞–Ω–∏—è', 'bye', '–ø—Ä–æ—â–∞–π']),
            'help': any(word in message_lower for word in ['–ø–æ–º–æ—â—å', 'help', '—á—Ç–æ —Ç—ã —É–º–µ–µ—à—å']),
            'explanation': any(word in message_lower for word in ['–æ–±—ä—è—Å–Ω–∏', '—Ä–∞—Å—Å–∫–∞–∂–∏', '—á—Ç–æ —Ç–∞–∫–æ–µ', '–∫–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç']),
            'code_request': any(word in message_lower for word in ['–∫–æ–¥', '–ø—Ä–∏–º–µ—Ä', '–Ω–∞–ø–∏—à–∏', '—Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π', '–ø–æ–∫–∞–∂–∏ –∫–æ–¥']),
            'comparison': any(word in message_lower for word in ['—Ä–∞–∑–Ω–∏—Ü–∞', '—Å—Ä–∞–≤–Ω–∏', '—á—Ç–æ –ª—É—á—à–µ', '–æ—Ç–ª–∏—á–∏–µ']),
            'problem': any(word in message_lower for word in ['–ø—Ä–æ–±–ª–µ–º–∞', '–æ—à–∏–±–∫–∞', '–Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç', '–ø–æ–º–æ–≥–∏ —Ä–µ—à–∏—Ç—å']),
            'opinion': any(word in message_lower for word in ['–º–Ω–µ–Ω–∏–µ', '–¥—É–º–∞–µ—à—å', '—Å—á–∏—Ç–∞–µ—à—å', '—Ç–æ—á–∫–∞ –∑—Ä–µ–Ω–∏—è']),
            'learning_path': any(word in message_lower for word in ['—Å —á–µ–≥–æ –Ω–∞—á–∞—Ç—å', '–∫–∞–∫ —É—á–∏—Ç—å', '–ø—É—Ç—å –æ–±—É—á–µ–Ω–∏—è', '–∏–∑—É—á–µ–Ω–∏–µ']),
            'feedback': any(word in message_lower for word in ['–æ—Ç–ª–∏—á–Ω–æ', '–ø–ª–æ—Ö–æ', '—Å–ø–∞—Å–∏–±–æ', '–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ', '—Ö–æ—Ä–æ—à–æ']),
        }
        
        return [intent for intent, detected in intents.items() if detected]
    
    def extract_entities(self, message):
        entities = {
            'languages': [],
            'technologies': [],
            'concepts': [],
            'level_indicators': []
        }
        
        for lang_key, lang_info in self.programming_languages.items():
            lang_name = lang_info['name'].lower()
            if (lang_key in message.lower() or lang_name in message.lower()):
                entities['languages'].append(lang_key)
        
        return entities
    
    def generate_smart_response(self, message):
        # –ê–Ω–∞–ª–∏–∑ intent'–∞ –∏ entities
        intents = self.analyze_intent(message)
        entities = self.extract_entities(message)
        
        # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –ª—É—á—à–∏–π –æ—Ç–≤–µ—Ç (—Å –≤–µ–±-–ø–æ–∏—Å–∫–æ–º –µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
        best_response = None
        best_confidence = 0.0
        response_source = "unknown"
        
        for intent in intents:
            response, confidence, source = self.learning_ai.find_best_response(
                message, intent, entities, use_web_search=True
            )
            if response and confidence > best_confidence:
                best_response = response
                best_confidence = confidence
                response_source = source
        
        # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ —Ö–æ—Ä–æ—à–∏–π –æ—Ç–≤–µ—Ç
        if best_response and best_confidence > 0.4:
            final_response = best_response
            if response_source == "web_search":
                self.learning_stats['web_searches'] += 1
                final_response = "üîç *–ù–∞—à–µ–ª –æ—Ç–≤–µ—Ç –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ:*\n\n" + final_response
        else:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–æ–≤—ã–π –æ—Ç–≤–µ—Ç
            final_response = self._craft_response(message, intents, entities)
            response_source = "generated"
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ–≤—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
            if response_source == "generated" and intents:
                primary_intent = intents[0]
                self.learning_ai.learn_from_conversation(
                    message, final_response, primary_intent, 
                    json.dumps(entities)
                )
                self.learning_stats['patterns_learned'] += 1
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self.learning_stats['conversations_processed'] += 1
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
        self.conversation_history.append({
            'message': message,
            'response': final_response,
            'intents': intents,
            'entities': entities,
            'response_source': response_source,
            'confidence': best_confidence,
            'timestamp': datetime.now()
        })
        
        if len(self.conversation_history) > 50:
            self.conversation_history = self.conversation_history[-25:]
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞-–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        source_emoji = {
            "manual": "üìö",
            "web_search": "üåê", 
            "web_cache": "üíæ",
            "generated": "üéØ"
        }
        
        final_response += f"\n\n{source_emoji.get(response_source, 'ü§ñ')} *–ò—Å—Ç–æ—á–Ω–∏–∫: {response_source}*"
        
        return final_response
    
    def _craft_response(self, message, intents, entities):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ intent'–æ–≤"""
        if 'greeting' in intents:
            return self._generate_adaptive_greeting()
        
        if 'farewell' in intents:
            return self._generate_farewell()
        
        if 'help' in intents:
            return self._generate_help_response()
        
        if 'explanation' in intents:
            return self._generate_explanation(message, entities)
        
        if 'code_request' in intents:
            return self._generate_code_example(message, entities)
        
        if 'feedback' in intents:
            return self._process_feedback(message)
        
        return self._generate_contextual_response(message, entities)
    
    def _generate_adaptive_greeting(self):
        """–ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ"""
        greetings = [
            "–ü—Ä–∏–≤–µ—Ç! –Ø —É–º–µ—é –∏—Å–∫–∞—Ç—å –æ—Ç–≤–µ—Ç—ã –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ –∏ –∑–∞–ø–æ–º–∏–Ω–∞—Ç—å –∏—Ö! üß†üåê",
            "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –¢–µ–ø–µ—Ä—å —è –º–æ–≥—É –∏—Å–∫–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–Ω–ª–∞–π–Ω! üöÄ",
            "–ü—Ä–∏–≤–µ—Ç! –ú–æ—è –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –ø–æ–ø–æ–ª–Ω—è–µ—Ç—Å—è –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞! üí´"
        ]
        return random.choice(greetings)
    
    def _generate_help_response(self):
        stats = self.get_learning_stats()
        
        help_text = f"""
ü§ñ **AI-GPT2 —Å –í–ï–ë-–ü–û–ò–°–ö–û–ú –∏ –ú–ê–®–ò–ù–ù–´–ú –û–ë–£–ß–ï–ù–ò–ï–ú**

üß† **–ú–æ–∏ –Ω–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:**
‚Ä¢ üîç **–ü–æ–∏—Å–∫ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ** - –µ—Å–ª–∏ –Ω–µ –∑–Ω–∞—é –æ—Ç–≤–µ—Ç
‚Ä¢ üíæ **–ê–≤—Ç–æ-—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ** - –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –∑–∞–ø–æ–º–∏–Ω–∞—é—Ç—Å—è
‚Ä¢ üåê **–†–∞–±–æ—Ç–∞ —Å –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏** - DuckDuckGo, Wikipedia
‚Ä¢ üìö **–†–∞—Å—à–∏—Ä–µ–Ω–∏–µ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π** –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏

üìä **–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—É—á–µ–Ω–∏—è:**
‚Ä¢ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –¥–∏–∞–ª–æ–≥–æ–≤: {stats['total_conversations']}
‚Ä¢ –í—ã—É—á–µ–Ω–æ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: {stats['patterns_learned']}
‚Ä¢ –í–µ–±-–ø–æ–∏—Å–∫–æ–≤: {stats['web_searches']}
‚Ä¢ –†–∞–∑–º–µ—Ä –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π: {stats['knowledge_base_size']}

üí° **–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤–µ–±-–ø–æ–∏—Å–∫:**
1. –í—ã –∑–∞–¥–∞–µ—Ç–µ –≤–æ–ø—Ä–æ—Å
2. –Ø –∏—â—É –≤ —Å–≤–æ–µ–π –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π
3. –ï—Å–ª–∏ –Ω–µ –Ω–∞—Ö–æ–∂—É - –∏—â—É –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ
4. –ù–∞–π–¥–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç —Å–æ—Ö—Ä–∞–Ω—è—é –≤ –±–∞–∑—É
5. –í —Å–ª–µ–¥—É—é—â–∏–π —Ä–∞–∑ –æ—Ç–≤–µ—á–∞—é –º–≥–Ω–æ–≤–µ–Ω–Ω–æ!

üöÄ **–¢–µ–ø–µ—Ä—å —è –ø–æ—Å—Ç–æ—è–Ω–Ω–æ —É—á—É—Å—å –∏ —Ä–∞—Å—à–∏—Ä—è—é –∑–Ω–∞–Ω–∏—è!**
"""
        return help_text

    def get_learning_stats(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è"""
        cursor = self.learning_ai.conn.cursor()
        cursor.execute('SELECT COUNT(*) FROM qa_patterns')
        knowledge_size = cursor.fetchone()[0]
        
        stats = {
            'total_conversations': self.learning_stats['conversations_processed'],
            'patterns_learned': self.learning_stats['patterns_learned'],
            'web_searches': self.learning_stats['web_searches'],
            'knowledge_base_size': knowledge_size
        }
        
        return stats

    # –û—Å—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã –æ—Å—Ç–∞—é—Ç—Å—è
    def _generate_code_example(self, message, entities):
        if entities['languages']:
            language = entities['languages'][0]
            examples = {
                'python': "```python\nprint('–ü—Ä–∏–≤–µ—Ç, –º–∏—Ä!')\n```",
                'javascript': "```javascript\nconsole.log('–ü—Ä–∏–≤–µ—Ç, –º–∏—Ä!');\n```", 
                'java': "```java\nSystem.out.println('–ü—Ä–∏–≤–µ—Ç, –º–∏—Ä!');\n```"
            }
            return f"–ü—Ä–∏–º–µ—Ä –Ω–∞ {language}:\n{examples.get(language, examples['python'])}"
        return "–ù–∞ –∫–∞–∫–æ–º —è–∑—ã–∫–µ –Ω—É–∂–µ–Ω –ø—Ä–∏–º–µ—Ä –∫–æ–¥–∞?"

class AIHandler(BaseHTTPRequestHandler):
    ai = SmartAI()
    
    def do_GET(self):
        if self.path == '/':
            self._serve_html()
        elif self.path == '/stats':
            self._serve_stats()
        else:
            self.send_error(404, "Not Found")
    
    def do_POST(self):
        if self.path == '/chat':
            self._handle_chat()
        else:
            self.send_error(404, "Not Found")
    
    def _serve_html(self):
        self.send_response(200)
        self.send_header('Content-type', 'text/html; charset=utf-8')
        self.end_headers()
        
        html = '''
        <!DOCTYPE html>
        <html>
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>AI-GPT2 —Å –í–µ–±-–ü–æ–∏—Å–∫–æ–º üß†üåê</title>
            <style>
                body { 
                    font-family: -apple-system, BlinkMacSystemFont, sans-serif; 
                    max-width: 800px; 
                    margin: 0 auto; 
                    padding: 20px; 
                    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                    min-height: 100vh;
                }
                .chat-container {
                    background: white;
                    border-radius: 20px;
                    padding: 25px;
                    box-shadow: 0 10px 30px rgba(0,0,0,0.3);
                    height: 90vh;
                    display: flex;
                    flex-direction: column;
                }
                .header {
                    text-align: center;
                    margin-bottom: 20px;
                    background: linear-gradient(135deg, #2c3e50, #3498db);
                    color: white;
                    padding: 20px;
                    border-radius: 15px;
                    margin: -25px -25px 20px -25px;
                }
                .learning-stats {
                    background: #e8f4fd;
                    padding: 15px;
                    border-radius: 10px;
                    margin: 10px 0;
                    border-left: 4px solid #3498db;
                }
                .stat-item {
                    display: flex;
                    justify-content: space-between;
                    margin: 5px 0;
                }
                .web-search-indicator {
                    background: #ffeb3b;
                    padding: 5px 10px;
                    border-radius: 15px;
                    font-size: 0.8em;
                    margin-left: 10px;
                    animation: pulse 2s infinite;
                }
                @keyframes pulse {
                    0% { opacity: 1; }
                    50% { opacity: 0.7; }
                    100% { opacity: 1; }
                }
                #chat {
                    flex: 1;
                    border: 2px solid #e1e5e9;
                    border-radius: 15px;
                    padding: 20px;
                    margin-bottom: 20px;
                    overflow-y: auto;
                    background: #f8f9fa;
                }
                .message {
                    margin: 15px 0;
                    padding: 15px 20px;
                    border-radius: 18px;
                    max-width: 85%;
                    line-height: 1.5;
                }
                .user {
                    background: linear-gradient(135deg, #007bff, #0056b3);
                    color: white;
                    margin-left: auto;
                    text-align: right;
                }
                .ai {
                    background: white;
                    color: #2c3e50;
                    border: 2px solid #3498db;
                }
                .source-web {
                    border-color: #ff9800;
                }
                .source-cache {
                    border-color: #4caf50;
                }
            </style>
        </head>
        <body>
            <div class="chat-container">
                <div class="header">
                    <h1>üß†üåê AI-GPT2 —Å –í–ï–ë-–ü–û–ò–°–ö–û–ú</h1>
                    <p>–ò–ò –∫–æ—Ç–æ—Ä—ã–π –∏—â–µ—Ç –æ—Ç–≤–µ—Ç—ã –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ –∏ –∑–∞–ø–æ–º–∏–Ω–∞–µ—Ç –∏—Ö!</p>
                    <div class="web-search-indicator">üîç –ê–ö–¢–ò–í–ï–ù –í–ï–ë-–ü–û–ò–°–ö</div>
                </div>
                
                <div class="learning-stats">
                    <h3>üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—É—á–µ–Ω–∏—è</h3>
                    <div class="stat-item">
                        <span>–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –¥–∏–∞–ª–æ–≥–æ–≤:</span>
                        <span id="conversationsCount">0</span>
                    </div>
                    <div class="stat-item">
                        <span>–í–µ–±-–ø–æ–∏—Å–∫–æ–≤:</span>
                        <span id="webSearches">0</span>
                    </div>
                    <div class="stat-item">
                        <span>–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π:</span>
                        <span id="knowledgeBase">0 –∑–∞–ø–∏—Å–µ–π</span>
                    </div>
                </div>
                
                <div id="chat">
                    <div class="message ai">
                        <strong>üß†üåê –ü—Ä–∏–≤–µ—Ç! –Ø AI-GPT2 —Å –≤–µ–±-–ø–æ–∏—Å–∫–æ–º!</strong><br><br>
                        üí° <strong>–ù–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:</strong><br>
                        ‚Ä¢ üîç <strong>–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫</strong> –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ<br>
                        ‚Ä¢ üíæ <strong>–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤</strong><br>
                        ‚Ä¢ üöÄ <strong>–ú–≥–Ω–æ–≤–µ–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã</strong> –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ –ø–æ–∏—Å–∫–∞<br><br>
                        üéØ <strong>–°–ø—Ä–æ—Å–∏—Ç–µ —á—Ç–æ-–Ω–∏–±—É–¥—å —Å–ª–æ–∂–Ω–æ–µ - —è –Ω–∞–π–¥—É –æ—Ç–≤–µ—Ç!</strong>
                    </div>
                </div>
                
                <div style="display: flex; gap: 10px;">
                    <input type="text" id="messageInput" placeholder="–°–ø—Ä–æ—Å–∏—Ç–µ –æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–∏..." style="flex: 1; padding: 15px; border: 2px solid #bdc3c7; border-radius: 25px;">
                    <button onclick="sendMessage()" style="padding: 15px 25px; background: #e74c3c; color: white; border: none; border-radius: 25px;">–û—Ç–ø—Ä–∞–≤–∏—Ç—å</button>
                </div>
            </div>

            <script>
                let stats = {
                    conversations: 0,
                    webSearches: 0,
                    knowledgeBase: 0
                };
                
                function addMessage(text, isUser, source) {
                    const chat = document.getElementById('chat');
                    const message = document.createElement('div');
                    message.className = isUser ? 'message user' : `message ai ${source ? 'source-' + source : ''}`;
                    message.innerHTML = text;
                    chat.appendChild(message);
                    chat.scrollTop = chat.scrollHeight;
                    
                    if (!isUser) {
                        stats.conversations++;
                        if (text.includes('üåê') || text.includes('–≤–µ–±-–ø–æ–∏—Å–∫')) {
                            stats.webSearches++;
                        }
                        updateStats();
                    }
                }

                async function sendMessage() {
                    const input = document.getElementById('messageInput');
                    const message = input.value.trim();
                    
                    if (!message) return;
                    
                    input.value = '';
                    addMessage(message, true);
                    
                    try {
                        // –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –∑–∞–≥—Ä—É–∑–∫–∏
                        const loadingMsg = addMessage('üîç –ü–æ–∏—Å–∫ –æ—Ç–≤–µ—Ç–∞...', false);
                        
                        const response = await fetch('/chat', {
                            method: 'POST',
                            headers: {'Content-Type': 'application/json'},
                            body: JSON.stringify({message: message})
                        });
                        
                        const data = await response.json();
                        
                        // –£–¥–∞–ª—è–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –∑–∞–≥—Ä—É–∑–∫–∏
                        chat.removeChild(loadingMsg);
                        
                        addMessage(data.response, false);
                        
                    } catch (error) {
                        addMessage('‚ùå –û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è', false);
                    }
                }

                async function updateStats() {
                    try {
                        const response = await fetch('/stats');
                        const data = await response.json();
                        
                        document.getElementById('conversationsCount').textContent = data.total_conversations;
                        document.getElementById('webSearches').textContent = data.web_searches;
                        document.getElementById('knowledgeBase').textContent = data.knowledge_base_size + ' –∑–∞–ø–∏—Å–µ–π';
                    } catch (error) {
                        document.getElementById('conversationsCount').textContent = stats.conversations;
                        document.getElementById('webSearches').textContent = stats.webSearches;
                        document.getElementById('knowledgeBase').textContent = Math.floor(stats.conversations * 1.5) + ' –∑–∞–ø–∏—Å–µ–π';
                    }
                }

                document.getElementById('messageInput').addEventListener('keypress', function(e) {
                    if (e.key === 'Enter') sendMessage();
                });

                // –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–∞—á–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                updateStats();
            </script>
        </body>
        </html>
        '''
        self.wfile.write(html.encode('utf-8'))
    
    def _serve_stats(self):
        """–û—Ç–¥–∞—á–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è"""
        stats = self.ai.get_learning_stats()
        
        self.send_response(200)
        self.send_header('Content-type', 'application/json')
        self.end_headers()
        
        self.wfile.write(json.dumps(stats).encode('utf-8'))
    
    def _handle_chat(self):
        try:
            content_length = int(self.headers['Content-Length'])
            post_data = self.rfile.read(content_length)
            data = json.loads(post_data.decode('utf-8'))
            message = data.get('message', '')
            
            response = self.ai.generate_smart_response(message)
            
            self.send_response(200)
            self.send_header('Content-type', 'application/json; charset=utf-8')
            self.end_headers()
            
            self.wfile.write(json.dumps({"response": response}).encode('utf-8'))
            
        except Exception as e:
            self.send_error(500, f"Error: {str(e)}")

if __name__ == '__main__':
    HOST = '0.0.0.0'
    PORT = 8000
    
    print("üß†üåê –ó–ê–ü–£–°–ö AI-GPT2 –° –í–ï–ë-–ü–û–ò–°–ö–û–ú...")
    print("‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó")
    print("‚ïë           AI-GPT2 —Å –í–µ–±-–ü–æ–∏—Å–∫–æ–º v2.0        ‚ïë")
    print("‚ïë      –°–∞–º–æ–æ–±—É—á–∞—é—â–∏–π—Å—è –ò–ò —Å –ø–æ–∏—Å–∫–æ–º –æ–Ω–ª–∞–π–Ω    ‚ïë")
    print("‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù")
    print(f"üìç –°–µ—Ä–≤–µ—Ä: http://localhost:{PORT}")
    print("\nüéØ –í–û–ó–ú–û–ñ–ù–û–°–¢–ò –í–ï–ë-–ü–û–ò–°–ö–ê:")
    print("‚Ä¢ üîç –ê–≤—Ç–æ–ø–æ–∏—Å–∫ –≤ DuckDuckGo, Wikipedia")
    print("‚Ä¢ üíæ –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤") 
    print("‚Ä¢ üìö –ê–≤—Ç–æ-–ø–æ–ø–æ–ª–Ω–µ–Ω–∏–µ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π")
    print("‚Ä¢ üöÄ –ú–≥–Ω–æ–≤–µ–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ –ø–æ–∏—Å–∫–∞")
    print("‚Ä¢ üåê –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤")
    
    try:
        server = HTTPServer((HOST, PORT), AIHandler)
        print(f"‚úÖ AI-GPT2 —Å –≤–µ–±-–ø–æ–∏—Å–∫–æ–º –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω –Ω–∞ {HOST}:{PORT}")
        print("üí° –¢–µ–ø–µ—Ä—å –ò–ò –º–æ–∂–µ—Ç –Ω–∞—Ö–æ–¥–∏—Ç—å –æ—Ç–≤–µ—Ç—ã –Ω–∞ –ª—é–±—ã–µ –≤–æ–ø—Ä–æ—Å—ã!")
        server.serve_forever()
    except KeyboardInterrupt:
        print("\nüõë AI-GPT2 –¥–µ–∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω")
        print("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ–±—É—á–µ–Ω–∏—è...")
